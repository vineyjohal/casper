# config.py

# Local LM Studio API URL
API_URL = "http://10.0.0.48:1234/v1/chat/completions"

# Model running in LM Studio
MODEL_NAME = "llama-3.2-3b-instruct"

# Optional settings
TEMPERATURE = 0.7


MEMORY_FILE = "casper_memory.json"